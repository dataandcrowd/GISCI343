---
title: "Programming Bootcamp: Part 2"
subtitle: ": Pandas"
date: 03/18/2025
date-format: long
author:
  - name: Hyesop Shin
    orcid: 0000-0003-2637-7933
    email: hyesop.shin@auckland.ac.nz
    affiliations:
      - name: University of Auckland
        address: 23 Symonds Street
        city: Auckland
        postal-code: 1010
format: 
  revealjs:
      logo: Figs/uoa-logo.png
      css: logo.css
      slide-number: true
      show-slide-number: print
editor: source
include-in-header:
  - text: |
      <style type="text/css">
      ul li ul li {
        font-size: 0.7em;
      }
      </style>
---


## Recap of Previous Lecture

-   Maths
-   How to assign variables, lists
-   For loops
-   Conditional statements
- spacing is important

## Terminology - Brackets

* To avoid any confusion between NZ and US English, I will use:
    - `[ ]` as square brackets
    - `( )` as round brackets
    - `{ }` as curly brackets
    - `< >` as angle(d) brackets 

## What will we cover this week?
- How can we better understand the code structure to query complicated datasets?
- How can we utilse Python Packages
- How does programming open up new methods for spatial analysis that are not possible through manual processes



## What will we "really" cover this week?
- How do we learn dictionaries?
-   How to import spreadsheet data with `pandas`
-   How to clean and explore data
-   Data Visualisation (tutorial class)

::: notes
:::


## Dictionaries
- A dictionary is another type of variable
- It is useful for storing loosely structured information
- It uses a key:value structure
- Denoted using curly brackets {}
- Often combined with a list
  
---

### Example

```python
census = {
                        "apple":"a delicious round fruit",
                        "bench":"a place to sit next to the footpath",
                        "candy":"something thats tastey but causes cavities",
                        "door":"a portal to another room",
                        "entomologist":"somone that studies bugs",
                        "farce":"a sausage meat mixture",
                        "gas":"a petrochemical nearing end of life",
                        "hatchback":"a car with a rear that enitrely opens",
                        "ice":"the solid state of water",
                        "juice":"a sugary taste fruit drink",
                        "k****":"asdfasdf",
                     }
GISCI_dictionary["bench"]

```

## Dictionary functions
- `mydict.keys()` gives you the 'key' of the key:value pairing
- `mydict.items()` give you the contents as a list
- `mydict.values()` gives you the values


```python
GISCI_dictionary.keys()
GISCI_dictionary.values()
GISCI_dictionary.items()

```

---

### We can use a for loop to run through the keys in dictionary:

```python
for i in GISCI_dictionary.keys():
    print(i)
```

---

### Or we could use it as a way to format a printing of the entire dictionary

```python
for i in GISCI_dictionary.keys(): # using the key we get from this line...
    print (i + ":\n\t" + GISCI_dictionary[i]) # ...to call the item/value from the dictionary as we loop through it
```

---

### Dictionaries are often multi layered (multi-dimensional)
- Often dictionaries contain lists of dictionaries
- Yes, it is confusing, but creates more freedom

::: {style="font-size: 70%;"}

```python
mydict = {"people":[
            {
                "name":"Hyesop",
                 "role":"teacher"
            },
            {
                "name":"Sila",
                 "role":"teacher"
            },
            {
                "name":"Oliver",
                 "role":"tutor"
            }    
            ]}
# print(mydict)
print(mydict["people"])
```
:::

---


### We can add another dictionary within that first one, that contains a totally different set of information...

```python
mydict = {"people":[
            {"name":"hyesop","role":"teacher"},
            {"name":"sila","role":"teacher"},
            {"name":"oliver","role":"tutor"},    
        ],
         "mascots":[
             {"name":"pepper","species":"dog"},
             {"name":"pip","species":"dog"},
             {"name":"harriet","species":"cat"}
         ]}
# print(mydict)
print(mydict["people"])
```


## Why use dictionaries?

::: {style="font-size: 80%;".incremental}
- Dictionaries are really useful as they create a bit more freedom in our data strucutre.
- In comparison, in array its a really bad idea to have mixed data types and uneven arrays, however dictionaries are great for this type of data.
- This moves us towards 'unstructured' data. Lots of the info we get from the web is fairly unstrucutred becasue it relies on non-complete datasets. 
  - For example: some data has geolocation, and some does not. 
- Having said that, using a dictionary doesn't mean _no_ structure, it just means that not all elements of the structure will be there. 
:::


---

###

![](Figs/geojson_io.png)


---


## Getting started with Pandas
* Packages
* Reading in files
* Filtering columns and rows
* `Group by` and `Aggregation`
* Merging dataframes
* Visulisation


## Packages

* In Python, you can do all sorts of thing beyond the basic python command
* You can do so using **packages**
* Do you recognise any of them?

![](data/ranks.png){fig-align=center}

## Installation

* Using **conda**: <br> in your terminal, `conda install pandas`
* Using **pip** or **pip3**: <br> in your terminal, `pip3 install pandas`

<br>

* However colab requires an exclamation mark in front of pip
* `!pip install pandas`

## Once installed you `import` libraries (or modules) {.smaller}

* In Python, you must specify which library a function comes from, even after importing it.
* To simplify this, assign a nickname (alias) when importing a library.
* Commonly used nicknames:
    - pandas → pd
    - numPy → np
    - matplotlib.pyplot → plt
    - seaborn → sns
* Using nicknames makes code more readable and efficient.

```python
import pandas as pd
import numpy as np
import matplotlib as plt
```

## Reading in Files

![](https://pandas.pydata.org/docs/_images/02_io_readwrite.svg)


```python
import pandas as pd

df = pd.read_csv('file_name')
df.to_csv(file_name, sep='\t', encoding='utf-8')
df.to_excel("output.xlsx") 
```
---

### Import/Export different file types
* `.csv`
* `.txt`
* `.xlsx`
* `.json`
* ...

---

### However in Colab

* After you upload your files you can run these codes (refer to the Google Colab link)

```
# method 1
with open('/content/drive/My Drive/example.txt', 'r') as f:
    text = f.read()
print(text)

# method 2
import pandas as pd
data = pd.read_csv('/content/drive/My Drive/my_data/data.csv')
print(data.head())
```
* Fore detailed info: [https://saturncloud.io/blog/google-colab-how-to-read-data-from-my-google-drive/](https://saturncloud.io/blog/google-colab-how-to-read-data-from-my-google-drive/)




## What is a dataframe

![](https://media.geeksforgeeks.org/wp-content/uploads/finallpandas.png){fig-align=center}

::: {style="font-size: 50%;"}
source: geeksforgeeks.org
:::

* Tabular array 
* Might be a stack of lists (recap of last lecture) 
* A combined data series

___

### A toy DataFrame

```python
pandas_df = pd.DataFrame({'a': [1,2,3,4], 
                          'b': [5,6,7,8]})
pandas_df
```

---

### Your turn

```python
import pandas as pd

# intialise data of lists.
data = {'Name':['Tom', 'nick', 'krish', 'jack'],
        'Age':[20, 21, 19, 18]}
        
# Create DataFrame
df = pd.DataFrame(data)

# Print the output.
print(df)

## Always check using these functions

```python
pandas_df.columns # print the pandas column names
pandas_df.shape # Dimension
pandas_df.type()
pandas_df.describe()
```


## DataFrame vs Data series?

* A Series is a 1-dimensional data structure used to represent a single column or row of data within a DataFrame or as a standalone data structure.
* A DataFrame is a 2-dimensional data structure designed for handling tabular data with multiple columns

![](https://av-eks-blogoptimized.s3.amazonaws.com/series-and-dataframe.png){fig-align=center}




### Understanding the data structure
* The info methods and the dtypes attribute are convenient for a first check.


```python
df.info() ## technical summary (e.g. dataframe, rows/columnns and their names)
df.dtypes ## generic summary
```

<br>

* `head`/`tail` to check how the dataframe actually looks like


```python
df.head()
df.tail()
```


## Dot Syntax and Methods in Python

- The **dot (`.`) syntax** is used for both:  
  - Extracting attributes → `object.attribute`  
  - Applying object-specific functions → `object.method()`  

- **Methods** are functions specific to an object's type.  

- Example with a **pandas DataFrame (`pandas_df`)**:  
  - Compute the mean of each column:  
    ```python
    pandas_df.mean()
    ```  
  - Compute the sum of each column:  
    ```python
    pandas_df.sum()
    ```  

- Methods are called using **`object.method()`** format.

---

### libraries can be confusing

* Does this work?

```python
py_list = [1, 3, 4]
py_list.mean()
```
* If not, why doesn't it work?
* Can you come up with a solution?


## Indexing DataFrames

### Extracting columns
While you can create a pandas DataFrame using a dictionary containing list entries (as we did earlier), the columns of a DataFrame themselves, when extracted, are a “Series” type object (rather than a list).


```python
pandas_df['a'] # the column 'a' can be extracted using []

pandas_df.a # df.col dot syntax
```
* The output above is the same as from the pandas_df['a'] syntax: both outputs are a pandas Series object.


---

<!-- ### Subsetting the data frame: Columns -->

<!-- ![](https://pandas.pydata.org/docs/_images/03_subset_columns.svg) -->

<!-- * Selecting a single column -->
<!-- * Selecting multiple columns -->

<!-- ::: {style="font-size: 80%;"} -->
<!-- * When selecting subsets of data, `[]` are used. -->
<!-- * Inside `[]`, you can use a single column/row label, a list of column/row labels, a slice of labels, a conditional expression or a colon. -->
<!-- * `loc` when selecting the row and column names e.g. census["age"] -->
<!-- * `iloc` when specifying the positions in the table e.g. census[2:5] -->
<!-- * You can assign new values to a selection based on `loc`/`iloc.` -->
<!-- ::: -->


<!-- ```python -->
<!-- census["Name"] -->
<!-- census[["Name", "pop23_ov65"]] -->
<!-- census.iloc[:, 3] -->
<!-- ``` -->


### Adding columns to a DataFrame

* You can define a new DataFrame using an existing data frame and then modify it, e.g., by adding a new column:

```python
# define a new data frame using the original one
pandas_df_new = pandas_df
# add a new column to the new data frame
pandas_df_new['d'] = [13,14,15,16]
# print out the new data frame
pandas_df_new
```

Notice that the original DataFrame will also change:

```python
pandas_df
```

```
   a  b   c   d
0  1  5   9  13
1  2  6  10  14
2  3  7  11  15
3  4  8  12  16
```

## Don’t forget to `.copy()`

1. **Assignment in Python Creates a Reference, Not a Copy**  
   When you assign one variable to another, like this:
   
   ```python
   pandas_df_new = pandas_df
   ```
   
   - You are **not** creating a new DataFrame.  
   - Instead, `pandas_df_new` becomes another **name (or pointer)** for the same underlying object (`pandas_df`).  
   - Any changes made to `pandas_df_new` will also **modify** `pandas_df` because they both reference the same data in memory.

---

### 2. Example of the Problem  {.smaller}

   ```python
   import pandas as pd
   
   pandas_df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})
   pandas_df_new = pandas_df
   pandas_df_new['A'] = [10, 20, 30]
   print(pandas_df)  # The original DataFrame is also modified!
   ```

**Output:**

   ```
       A  B
   0  10  4
   1  20  5
   2  30  6
   ```

   - Notice that `pandas_df` changed even though we only modified `pandas_df_new`.  
   - This happens because `pandas_df_new` is just another reference to the same object.

---

### 3. Solution: Use `.copy()` to Create a True Copy

```python
pandas_df_new = pandas_df.copy()
```

   - Now, `pandas_df_new` is a completely **separate** DataFrame.  
   - Changes made to `pandas_df_new` **won’t** affect `pandas_df`.


## 4. Example with `.copy()` {.smaller}

   ```python
   import pandas as pd

   # Create a DataFrame
   pandas_df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})

   # Create a true copy
   pandas_df_new = pandas_df.copy()

   # Modify the new DataFrame
   pandas_df_new['A'] = [10, 20, 30]

   print("Original DataFrame:\n", pandas_df)
   print("\nNew DataFrame:\n", pandas_df_new)
   ```

   **Output:**
   
   ```
   Original DataFrame:
       A  B
   0  1  4
   1  2  5
   2  3  6

   New DataFrame:
       A  B
   0  10  4
   1  20  5
   2  30  6
   ```
   
   - Now, `pandas_df` remains **unchanged**, because `pandas_df_new` is an independent copy.

## Your turn

* recreate a dataframe using the code below
* copy the dataframe and assign the new dataframe as `pandas_df_new`
* add a new column called 'c', with a list of [9,10,11,12]
* print the result for both `pandas_df` and `pandas_df_new` 

```python
pandas_df = pd.DataFrame({'a': [1,2,3,4], 
                          'b': [5,6,7,8]})
pandas_df
```

## Filtering (subsetting rows)

![](https://pandas.pydata.org/docs/_images/03_subset_rows.svg)

* Pandas Series objects: you can ask logical questions of them (side-note: this does not work with python lists, but it does with with pandas Series objects):

```python
# ask which entries in the column "a" are greater than 1
pandas_df['a'] > 1
```

```
0    False
1     True
2     True
3     True
Name: a, dtype: bool
```

## The Logic of location `loc` {.smaller}

1. employ the .loc method and
2. provide : to the column dimension (which says to “return all of the columns”), then we get the expected result:

```python
pandas_df.loc[pandas_df.a > 1,:]
```

```
   a  b
1  2  6
2  3  7
3  4  8
```

* Note that loc isn’t a normal function per se in that it is not followed by round brackets (), but it is followed by the square brackets [].

* If we wanted to just return the second column, we would provide the second column’s name ('b') into the second dimension of the .loc[,] square brackets

```python
pandas_df.loc[pandas_df.a > 1,'b']
```
```
1    6
2    7
3    8
Name: b, dtype: int64
```

## `iloc`

However, loc expects either a Boolean series or a name in its index. The iloc method, on the other hand, takes integer index positions. The following code will extract the second, third, and fourth rows of the second column (remember zero-indexing!).

```python
pandas_df.iloc[[1,2,3],1]
```

```
1    6
2    7
3    8
Name: b, dtype: int64
```

It’s a bit annoying that you can’t use the same syntax to do both named (`.loc`) and integer (`.iloc`) indexing for pandas DataFrames.

## The `query()` method {.smaller}

Since this type of square bracket syntax for indexing feels clunky in Python, you can alternatively use the `query()` method of a pandas DataFrame similar to the `filter()` function in the polar package

For pandas DataFrame, the `query()` syntax looks like

```python
pandas_df.query('a > 1')
```

```
   a  b
1  2  6
2  3  7
3  4  8
```

If you want to use an external variable, you need to access it using @ within the query argument:

```python
thresh = 1
pandas_df.query('a > @thresh')
```


## Your Turn

1. Create a dictionary with New Zealand city names as keys and their populations as values.

```python
nz_cities = {
    "Auckland": 1672000,
    "Wellington": 217200,
    "Christchurch": 389700,
    "Hamilton": 185000,
    "Tauranga": 158000,
    "Dunedin": 134600
}
```

2. Convert this to a dataframe

```python
`nzpop = pd.DataFrame(nz_cities.items(), columns=['city', 'population'])`
```

3. Use three methods to extract the Auckland population. Hint: use `loc`, `iloc`, and `query`





## <br> Grouping and Aggregation

---

### Grouping (in `Pandas`)

:::: {.columns}

::: {.column width="40%"}

![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSiUr0NSceFvB3vYV39lO01DRDld0HGEONzBiPZZCGUUQ&s){width=100%}

::: {style="font-size: 50%;"}
Source: Soner Yıldırım [Towards Data Science](https://towardsdatascience.com/all-about-pandas-groupby-explained-with-25-examples-494e04a8ef56)
:::
:::

::: {.column width="15%"}

:::

::: {.column width="45%"}
::: {style="font-size: 80%;"}

Grouping is used to group data using some criteria from our dataset. It is used as split-apply-combine strategy.

* *Splitting* the data into groups based on some criteria e.g. Brand
* *Applying* a function to each group independently e.g. Mean
* *Combining* the results into a data structure e,g, Price

:::
:::
::::


---

### `Groupby` function
- `groupby` allows us to summarize categorical values in a series
    - Excel has this function...
    - Pandas does it better/on more data!

```python
pandas_df = pd.DataFrame({'a': [1,2,3,4], 
                          'b': [5,6,7,8]})
pandas_df["cat"] = ["red","red","yellow","yellow"] # add a new categorical column to pandas_df
print(pandas_df)
```

```python
pandas_df.groupby('cat')["a"].mean()
pandas_df.groupby('cat').mean()
```


## Data Visualisation {.smaller}

In python there are many different libraries for doing data visualization. The two you are most likely to have heard of include matplotlib and seaborn.


Seaborn is a little prettier than matplotlib, but all I’m going to show in this tutorial is the inbuilt data visualisation methods for pandas Series and DataFrame objects that are built on matplotlib.


![](https://media.geeksforgeeks.org/wp-content/uploads/20210120122658/seaborntutorialpairplot.png){fig-align=center}



## Example: Gapminder

To do some more interesting vis, let’s load the gapminder dataset (from a URL) into a pandas DataFrame using the pd.read_csv() pandas function. This pd.read_csv() function can also be used to load a local .csv file.

```python
gapminder = pd.read_csv("https://raw.githubusercontent.com/rlbarter/gapminder-data/main/gapminder.csv")
```
Let’s use the head() DataFrame method to look at the first 5 rows:

```python
gapminder.head()
```

```
       country continent  year  lifeExp       pop   gdpPercap
0  Afghanistan      Asia  1952   28.801   8425333  779.445314
1  Afghanistan      Asia  1957   30.332   9240934  820.853030
2  Afghanistan      Asia  1962   31.997  10267083  853.100710
3  Afghanistan      Asia  1967   34.020  11537966  836.197138
4  Afghanistan      Asia  1972   36.088  13079460  739.981106
```

---

### Let's practise some of our new python skills

The following code will filter to the data for Australia and compute the mean life expectancy:

```python
gapminder.query('country == "Australia"')['lifeExp'].mean()
# 74.66291666666667
```

And the following will compute the average gdpPercap by continent:


```python
gdp_by_continent = gapminder.groupby('continent')['gdpPercap'].mean()
print(gdp_by_continent)
```

```
continent
Africa       2193.754578
Americas     7136.110356
Asia         7902.150428
Europe      14469.475533
Oceania     18621.609223
Name: gdpPercap, dtype: float64
```

## Shall we plot now?

Notice that the output of this last piece of code is a Series object. Notice also that the (row) index is the continent:

```
gdp_by_continent.index
```

```
Index(['Africa', 'Americas', 'Asia', 'Europe', 'Oceania'], dtype='object', name='continent')
```

What will happen if we apply the plot() method to this Series object?

```
gdp_by_continent.plot()
```

![](https://rebeccabarter.com/blog/2023-09-11-from_r_to_python_files/figure-html/unnamed-chunk-60-1.png){fig-align=center}

## Bar plot

* By default a line plot is created and the row index is used as the x-axis labels by default. The DataFrame’s `plot()` method here acts as a wrapper for the matplotlib library’s plotting function.

* If I wanted a bar chart instead of a line plot, I could create one using the plot.bar() method (instead of just the `plot()` method):

```python
gdp_by_continent.plot.bar()
```

![](https://rebeccabarter.com/blog/2023-09-11-from_r_to_python_files/figure-html/unnamed-chunk-61-3.png){fig-align=center}


## Merge df's
* Concatenate DataFrames along row and column.
* Merge DataFrames on specific keys by different join logics like `left join`, `inner join`, etc.
* Join DataFrames by index.

![](https://media.geeksforgeeks.org/wp-content/uploads/joinimages.png){fig-align=center}

---

### We have two dataframes

```python
# Creating the first DataFrame
df1 = pd.DataFrame({
    'ID': [1, 2, 3, 4],
    'Name': ['Tom', 'Nick', 'Krish', 'Jack'],
    'Age': [20, 21, 19, 18]
})

# Creating the second DataFrame
df2 = pd.DataFrame({
    'ID': [3, 4, 5, 6],
    'Subject': ['Maths', 'English', 'Science', 'History'],
    'Score': [88, 75, 90, 85]
})

print("DataFrame 1:")
print(df1)
print("\nDataFrame 2:")
print(df2)
```

----

### Inner Merge

An inner merge combines DataFrames based on the intersection of their keys.

```python
inner_merge = pd.merge(df1, df2, on='ID', how='inner')
print(inner_merge)
```
---

### Left/Right Merge

A left merge includes all rows from the left DataFrame and the matched rows from the right DataFrame.


```python
left_merge = pd.merge(df1, df2, on='ID', how='left')
print(left_merge)
```

---

### Outer Merge

```python
outer_merge = pd.merge(df1, df2, on='ID', how='outer')
print(outer_merge)
```




## Summary
* To navigate complex datasets effectively, it's crucial to structure your code in a way that enhances readability and maintainability
* Python offers a rich ecosystem of libraries specifically designed for GIS and spatial analysis. We explored some key packages such as GeoPandas for spatial data frames
* The actual programming:
    - Pandas: Indexing, Filtering, Grouping, Join between dataframes
    - Geopandas: Hands-on experience in GIS using codes




## <br> Thanks! <br> Q & A {style="text-align: center;"}
