{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 3 - Dictionaries, Pandas, and Geopandas\n",
    "![](images/panda.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](images/UoA_missing_map_poster.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A cool thing I saw on the net this week:\n",
    "Open Street Map and LLMs (GPT)\n",
    "https://github.com/rowheat02/osm-gpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Objectives\n",
    "- Dictionaries\n",
    "  - What, why, how\n",
    "- Pandas\n",
    "  - The industry and scientific standard means of tabular data handling*\n",
    "  - https://pandas.pydata.org/\n",
    "- Geopandas\n",
    "  - Making pandas spatial!\n",
    "  - https://geopandas.org/en/stable/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dictionaries\n",
    "- A dictionary is another type of variable\n",
    "  - It is useful for storing loosely structured information\n",
    "  - It uses a key:value structure\n",
    "  - Denoted using curly brackets {}\n",
    "  - Often combined with a list\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "GISCI_dictionary = {\n",
    "                        \"apple\":\"a delicious round fruit\",\n",
    "                        \"bench\":\"a place to sit next to the footpath\",\n",
    "                        \"candy\":\"something thats tastey but causes cavities\",\n",
    "                        \"door\":\"a portal to another room\",\n",
    "                        \"entomologist\":\"somone that studies bugs\",\n",
    "                        \"farce\":\"a sausage meat mixture\",\n",
    "                        \"gas\":\"a petrochemical nearing end of life\",\n",
    "                        \"hatchback\":\"a car with a rear that enitrely opens\",\n",
    "                        \"ice\":\"the solid state of water\",\n",
    "                        \"juice\":\"a sugary taste fruit drink\",\n",
    "                        \"k****\":\"asdfasdf\",\n",
    "                     }\n",
    "GISCI_dictionary[\"bench\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GISCI_dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dictionary functions\n",
    "- mydict.keys() gives you the 'key' of the key:value pairing\n",
    "- mydict.items() give you the contents as a list\n",
    "- mydict.values() gives you the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment each line of code one by one and check out what is returned by each function call\n",
    "webstersDictionary.keys()\n",
    "# webstersDictionary.values()\n",
    "# webstersDictionary.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# We can use a for loop to run through the keys in dictionary:\n",
    "for i in webstersDictionary.keys():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Or we could use it as a way to format a printing of the entire dictionary\n",
    "for i in webstersDictionary.keys(): # using the key we get from this line...\n",
    "    print (i + \":\\n\\t\" + webstersDictionary[i]) # ...to call the item/value from the dictionary as we loop through it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dictionaries are often multi layered (multi-dimensional)\n",
    "- Often dictionaries contain lists of dictionaries\n",
    "- Yes, it is confusing, but creates more freedom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Here a multi-level ditionary lets us store the variable 'people, \n",
    "# Within which we can then store more information about those people, in another dictionary.\n",
    "mydict = {\"people\":[\n",
    "            {\n",
    "                \"name\":\"michael\",\n",
    "                 \"role\":\"teacher\"\n",
    "            },\n",
    "            {\n",
    "                \"name\":\"sila\",\n",
    "                 \"role\":\"teacher\"\n",
    "            },\n",
    "            {\n",
    "                \"name\":\"amber\",\n",
    "                 \"role\":\"tutor\"\n",
    "            }    \n",
    "            ]}\n",
    "# print(mydict)\n",
    "print(mydict[\"people\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# We can add another dictionary within that first one, that contains a totally different set of information...\n",
    "mydict = {\"people\":[\n",
    "            {\"name\":\"michael\",\"role\":\"teacher\"},\n",
    "            {\"name\":\"sila\",\"role\":\"teacher\"},\n",
    "            {\"name\":\"amber\",\"role\":\"tutor\"},    \n",
    "        ],\n",
    "         \"mascots\":[\n",
    "             {\"name\":\"pepper\",\"species\":\"dog\"},\n",
    "             {\"name\":\"pip\",\"species\":\"dog\"},\n",
    "             {\"name\":\"harriet\",\"species\":\"cat\"}\n",
    "         ]}\n",
    "# print(mydict)\n",
    "print(mydict[\"people\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Combine this multi-level dictionary with a for loop and a conditional statement...\n",
    "for i in mydict[\"mascots\"]: #for every 1st level dict with this key...\n",
    "    print(str(i))\n",
    "    if i[\"species\"] == \"cat\":        # Within that dict, if the value of the key 'species' is cat...\n",
    "        print (\"all hail our new ruler! bow to \"+i[\"name\"]+\"!\") # Do this...\n",
    "    else:\n",
    "        print (\"who\\'s the best? \\n\\t\"+i[\"name\"]+\"\\'s the best!\\n\") # Otherwise do this.\n",
    "        \n",
    "# And we get the ability to selectively call and use data from different levels within it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why use dictionaries?\n",
    "- Dictionaries are really useful as they create a bit more freedom in our data strucutre.\n",
    "- In comparison, in array its a really bad idea to have mixed data types and uneven arrays, however dictionaries are great for this type of data.\n",
    "<br></br>\n",
    "- This moves us towards 'unstructured' data. Lots of the info we get from the web is fairly unstrucutred becasue it relies on non-complete datasets. \n",
    "  - For example: some data from Twitter (or X as it is now known, booooo) has geolocation, and some does not. \n",
    "  <br></br>\n",
    "- Having said that, using a dictionary doesn't mean _no_ structure, it just means that not all elements of the strucutre will be there. \n",
    "  - For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Here we have some pretty unstructured data as a dict...\n",
    "mydict = {\n",
    "    \"restaurants\":[\n",
    "        {\n",
    "            \"name\":\"McDonalds\",\n",
    "            \"nickname\":\"Maccas\",\n",
    "            \"known-for\":\"Big Mac\",\n",
    "            \"likely-result\":\"heart-Attack\",\n",
    "            \"rating\":3.3            \n",
    "        },\n",
    "        {\n",
    "            \"name\":\"Burger King\",\n",
    "            \"nickname\":\"The King\",\n",
    "            \"known-for\":\"Whopper\",\n",
    "            \"rating\":2\n",
    "        },\n",
    "        {\n",
    "            \"name\":\"Burger Wisconsin\",\n",
    "            \"nickname\":\"Burg-Wickies\",\n",
    "            \"known-for\":\"Expensive Trash!\",            \n",
    "        },\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Here it is as a complex array but... \n",
    "restaurants = [\"McDonalds\",\"Burger King\",\"Burger Wisconsin\"]\n",
    "nicknames = [\"Maccas\",\"The King\",\"Burg-Wickies\"]\n",
    "known_for = [\"Big Mac\",\"Whopper\",\"Expensive Trash\"]\n",
    "likely_result = [\"heart attack\",None,None]\n",
    "rating = [3.3,2,None]\n",
    "\n",
    "# It's messy and not easy to access items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# For example, let's try to get the info of the first record...\n",
    "print(restaurants[0]+\", nickname:\"+nicknames[0]+\", known for:\"+known_for[0]+\", likely result:\"+likely_result[0]+\", rating:\"+str(rating[0]))\n",
    "\n",
    "# Ok that worked, but what about the second record?\n",
    "#print(restaurants[1]+\", nickname:\"+nicknames[1]+\", known for:\"+known_for[1]+\", likely result:\"+likely_result[1]+\", rating:\"+str(rating[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Let's compare that to using the key from a dictionary for the broad class and...\n",
    "# ... then an index call the specific record (try 0, then try 1)\n",
    "print(mydict.keys())\n",
    "mydict[\"restaurants\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# In addition to accessing those individal records, when can of course call the whole dictionary\n",
    "print(mydict[\"restaurants\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### This is hard to see... I want only the ratings for my map, thanks.\n",
    "- Use a loop to get each restaurant, set the inner dictionary to be the variable 'r'\n",
    "- Once we have 'r' we ask for the ratings..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Let's try this... loop over all records in the restaurants dict and access their rating.\n",
    "mydict = {\"restaurants\":[\n",
    "        {   \"name\":\"McDonalds\",\n",
    "            \"nickname\":\"Maccas\",\n",
    "            \"known-for\":\"Big Mac\",\n",
    "            \"likely-result\":\"heart-Attack\",\n",
    "            \"rating\":3.3},\n",
    "        {   \"name\":\"Burger King\",\n",
    "            \"nickname\":\"The King\",\n",
    "            \"known-for\":\"Whopper\",\n",
    "            \"rating\":2},\n",
    "        {   \"name\":\"Burger Wisconsin\",\n",
    "            \"nickname\":\"Burg-Wickies\",\n",
    "            \"known-for\":\"Expensive Trash!\"},]}\n",
    "\n",
    "for resto in mydict[\"restaurants\"]:\n",
    "    print(resto[\"rating\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Ah, zut alors!\n",
    "- A record is completely missing a bit of information!\n",
    "- Lets fix this using a simple if statement\n",
    "- [Lets google that for us](https://www.bing.com/search?q=python+dictionary+keyerror&qs=n&form=QBRE&sp=-1&pq=python+dictionary+keyerror&sc=3-26&sk=&cvid=239D59BE272A4BE19C94C9B98C874DF0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# hmm. Error!!\n",
    "# A key error is given when we are trying to return the value of a dict key that doesn't exist.\n",
    "# Also we can use a method of the dict variable type mydict.get().\n",
    "# get() returns the value or None (the null value) if there is something there.\n",
    "# We can use this with a if statement to see if it exists!\n",
    "\n",
    "for i in mydict[\"restaurants\"]: # Again, loop over all the restaurants\n",
    "    if (i.get(\"rating\") != None): # IF a record has the rating key, use it\n",
    "        print(i[\"rating\"])\n",
    "    else:\n",
    "        print(\"No rating for\"+str(i[\"name\"])) # ELSE if there is no rating key, handle the error\n",
    "\n",
    "        \n",
    "# Clean it up a bit... \n",
    "# for i in mydict[\"Restaurants\"]: \n",
    "#     if (i.get(\"rating\")!=None): print(i[\"name\"]+\"'s rating is:\"+str(i[\"rating\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pandas\n",
    "![](images/panda.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Pandas\n",
    "![](images/pandas_logo.jpg)\n",
    "\n",
    "- What is pandas?\n",
    "  - Pandas is a _very_ powerful data handling and processing library for Python. \n",
    "  - It has a blazing fast ability to load and save data from a wide variety of formats (csv,json,excel, etc)\n",
    "  - It can transform data very quickly, too.\n",
    "- How do I get it?\n",
    "  - Run command prompt from anaconda\n",
    "    - If you forget how, have a look at last week's lecture :)\n",
    "  - Type: pip install pandas\n",
    "    - if you are having toruble with this, check in with us in lecture or lab time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Introducing, the dataframe\n",
    "- Pandas is all organized around a concept called a DataFrame\n",
    "- The dataframe is a powerful 2D array\n",
    "- Pandas brings data transformation, statistical analys, and plotting/visualization directly to you\n",
    "![](images/pandas_dataframe.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# To get started, we need to import the pandas library\n",
    "# if you get lost in class today, I highly recommend the pandas website\n",
    "# the tutorials on the site are excellent!\n",
    "# https://pandas.pydata.org/docs/getting_started\n",
    "import pandas as pd\n",
    "\n",
    "# To make a dataframe we can easily construct one ourselves...\n",
    "# ...creating a DataFrame using a dictionary.\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Name\":[\n",
    "            \"Braund, Mr. Owen Harris\",\n",
    "            \"Allen, Mr. William Henry\",\n",
    "            \"Bonnell, Miss. Elizabeth\",\n",
    "        ],\n",
    "        \n",
    "        \"Sex\": [\"male\", \"male\", \"female\"],\n",
    "        \"Age\": [22, 35, 58],\n",
    "    })\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/Age.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Query the table, asking for a single column of information\n",
    "- In pandas, a column is a 'series'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Get a series (column) of data\n",
    "df[\"Name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[[\"Name\", \"pop23_ov65\"]])\n",
    "\n",
    "print(df.iloc[:, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"Name\"] == \"Waitemata Local Board Area\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Code                        Name  pop13_u15  pop13_1529  pop13_3064  \\\n",
      "85  7610  Waitemata Local Board Area       7881       29865       34473   \n",
      "\n",
      "    pop13_ov65  pop13_tot  pop18_u15  pop18_1529  pop18_3064  pop18_ov65  \\\n",
      "85        4914      77136       7818       30387       38118        6543   \n",
      "\n",
      "    pop18_tot  pop23_u15  pop23_1529  pop23_3064  pop23_ov65  pop23_tot  \n",
      "85      82866       7206       26775       39333        8232      81546  \n"
     ]
    }
   ],
   "source": [
    "ov10m_old = df[(df[\"pop23_ov65\"] > 1000) & (df[\"Name\"] == \"Waitemata Local Board Area\") ]\n",
    "print(ov10m_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Code                                Name  pop13_u15  pop13_1529  \\\n",
      "0    3500             South Taranaki District       6078        4788   \n",
      "1    2000                    Waitomo District       2133        1584   \n",
      "2    7500                   Invercargill City      10254        9891   \n",
      "3    7604          Kaipatiki Local Board Area      15993       17985   \n",
      "4    7620           Papakura Local Board Area      11136        9864   \n",
      "5    7618   Otara-Papatoetoe Local Board Area      19605       18951   \n",
      "6   99900  Area Outside Territorial Authority          3           3   \n",
      "7    7300                  Southland District       6531        4980   \n",
      "8    5100                     Tasman District       9432        6387   \n",
      "9    3600                    Ruapehu District       2766        2175   \n",
      "10   6200                     Selwyn District       9933        7977   \n",
      "11   7200                     Clutha District       3501        2658   \n",
      "12   6300                  Ashburton District       6423        5307   \n",
      "13   7601             Rodney Local Board Area      11412        8253   \n",
      "14   3000                   Hastings District      16758       12519   \n",
      "15   1300                    Waikato District      15204       10695   \n",
      "16   3700                  Whanganui District       8517        7065   \n",
      "17   5300                Marlborough District       7752        6378   \n",
      "18   5700                   Westland District       1533        1305   \n",
      "19   6900              Central Otago District       3258        2172   \n",
      "\n",
      "    pop13_3064  pop13_ov65  pop13_tot  pop18_u15  pop18_1529  pop18_3064  \\\n",
      "0        11802        3909      26580       6219        4719       12264   \n",
      "1         3972        1218       8907       2082        1701        4071   \n",
      "2        23250        8301      51696      10560       10053       24249   \n",
      "3        39051        9462      82494      16449       20094       41472   \n",
      "4        19437        5196      45636      13632       13155       24786   \n",
      "5        30588        6516      75663      20610       23328       34233   \n",
      "6           36          12         51          3           6          18   \n",
      "7        14073        4026      29613       6534        5262       14436   \n",
      "8        22872        8463      47157       9534        7626       24258   \n",
      "9         5334        1569      11844       2715        2208        5454   \n",
      "10       21855        4833      44595      13452       10833       29301   \n",
      "11        8073        2655      16890       3411        2898        8271   \n",
      "12       14115        5196      31041       6810        5937       14697   \n",
      "13       26526        8688      54882      13251       10746       31323   \n",
      "14       32601       11364      73245      17697       14955       35199   \n",
      "15       29976        7503      63378      17724       13239       35130   \n",
      "16       18459        8109      42153       8937        7692       19371   \n",
      "17       20382        8907      43416       8259        7158       21378   \n",
      "18        4176        1293       8304       1449        1446        4212   \n",
      "19        8652        3810      17895       3651        2997       10005   \n",
      "\n",
      "    pop18_ov65  pop18_tot  pop23_u15  pop23_1529  pop23_3064  pop23_ov65  \\\n",
      "0         4332      27534       6171        4830       12906        5115   \n",
      "1         1446       9303       2022        1668        4197        1698   \n",
      "2         9345      54204      10233       10035       25083       10251   \n",
      "3        10251      88269      16125       17787       42936       11283   \n",
      "4         6063      57636      17130       15429       32829        6933   \n",
      "5         6951      85122      20448       21177       37566        7755   \n",
      "6            9         39          3           6          42          24   \n",
      "7         4635      30864       6387        5025       14874        5544   \n",
      "8        10974      52389       9498        8523       26322       13467   \n",
      "9         1932      12309       2799        2217        5688        2391   \n",
      "10        6975      60561      16659       13320       38031       10131   \n",
      "11        3087      17667       3408        2943        8436        3528   \n",
      "12        5982      33423       6714        5724       15447        6864   \n",
      "13       11094      66417      15225       11988       36972       13764   \n",
      "14       13689      81537      17541       15396       37716       15309   \n",
      "15        9525      75618      18675       14931       40224       12138   \n",
      "16        9309      45309       9042        7773       20205       10599   \n",
      "17       10548      47340       8232        7119       22239       11838   \n",
      "18        1536       8640       1377        1206        4437        1887   \n",
      "19        4908      21558       3894        3267       11163        5982   \n",
      "\n",
      "    pop23_tot  \n",
      "0       29025  \n",
      "1        9585  \n",
      "2       55599  \n",
      "3       88128  \n",
      "4       72318  \n",
      "5       86949  \n",
      "6          72  \n",
      "7       31833  \n",
      "8       57807  \n",
      "9       13095  \n",
      "10      78144  \n",
      "11      18315  \n",
      "12      34746  \n",
      "13      77949  \n",
      "14      85965  \n",
      "15      85968  \n",
      "16      47619  \n",
      "17      49431  \n",
      "18       8901  \n",
      "19      24306  \n"
     ]
    }
   ],
   "source": [
    "df.iloc[0:4, 2:5]\n",
    "print(df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Pandas makes statistically summarizing data easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# We can also simply ask pandas for stats\n",
    "# https://pandas.pydata.org/docs/getting_started/intro_tutorials/06_calculate_statistics.html\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### ...and we can make graphs really easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# We can also ask pandas for a really simple graph of the data\n",
    "# https://pandas.pydata.org/docs/getting_started/intro_tutorials/04_plotting.html\n",
    "df.plot.barh(x='Name',y='Age')\n",
    "\n",
    "# There are lots of different options for the type and styling of plots, far too much for today!\n",
    "# for example these are all the types of plots!\n",
    "#   'area','bar','barh','box','density', \n",
    "#   'hexbin', 'hist', 'kde', 'line', 'pie', 'scatter'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pandas and Dictionaries\n",
    "![](images/panda_dictionary_reading.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Re-set/ declare our dictionary once more...\n",
    "mydict = {\n",
    "    \"restaurants\":[\n",
    "        {\n",
    "            \"name\":\"McDonalds\",\n",
    "            \"nickname\":\"Maccas\",\n",
    "            \"known-for\":\"Big Mac\",\n",
    "            \"likely-result\":\"heart-Attack\",\n",
    "            \"rating\":3.3            \n",
    "        },\n",
    "        {\n",
    "            \"name\":\"Burger King\",\n",
    "            \"nickname\":\"The King\",\n",
    "            \"known-for\":\"Whopper\",\n",
    "            \"rating\":2\n",
    "        },\n",
    "        {\n",
    "            \"name\":\"Burger Wisconsin\",\n",
    "            \"nickname\":\"Burg-Wickies\",\n",
    "            \"known-for\":\"Expensive Trash!\",            \n",
    "        },\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pandas and dictionaries, a match made in paradise\n",
    "- You may have noticed in the code before that we are feeding pandas a dictionary\n",
    "- The dictionary is a lot like our restaurants data!\n",
    "  - But it is slightly different. \n",
    "    - Pandas set its dictionary up as the columns (series) as the dict keys\n",
    "    - The rows are arrays for each dict key. \n",
    "      - This means it is more 'strucutred'\n",
    "      \n",
    "![](images/unstructured-dict_vs_pandas.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Lets make our restaurant dict more pandas-like\n",
    "- We need to do two things. \n",
    "  1. Organize the strucutre into series and rows \n",
    "  2. Handle the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Remember our dictionary is mydict\n",
    "# Remember that I can use get() to return the key data i want OR None if it doesn't exist\n",
    "\n",
    "# set up a structure of the pandas data\n",
    "restos = {\n",
    "    \"name\":[], # The values are created empty here, ready get the data in\n",
    "    \"nickname\":[],\n",
    "    \"known-for\":[],\n",
    "    \"likely-result\":[],\n",
    "    \"rating\":[]\n",
    "}\n",
    "\n",
    "# We put the data into the dict using append\n",
    "for r in mydict[\"restaurants\"]:\n",
    "    restos[\"name\"].append(r.get(\"name\")) # the data or None if it does not exist\n",
    "    restos[\"nickname\"].append(r.get(\"nickname\"))\n",
    "    restos[\"known-for\"].append(r.get(\"known-for\"))\n",
    "    restos[\"likely-result\"].append(r.get(\"likely-result\"))\n",
    "    restos[\"rating\"].append(r.get(\"rating\"))           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "restos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Brilliant. Now lets turn that into a pandas dataframe...\n",
    "\n",
    "resto_df = pd.DataFrame(restos)\n",
    "resto_df\n",
    "\n",
    "# oooo look what pandas as done with that missing data... (None vs Nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pandas makes transforming data easy\n",
    "- We could get some stats and make a plot\n",
    "  - If you don't have matplotlib installed, you'll need to do so\n",
    "    - Open cmd.exe prompt from anaconda\n",
    "    - Type: conda install matplotlib\n",
    "- Pandas has a LOT of functionality, we can only really scratch the surface\n",
    "  - We will look at: \n",
    "    - Creating dataframes\n",
    "    - Making plots\n",
    "    - Making statistical summaries\n",
    "    - Grouping information\n",
    "    - Getting the head and tail of a large set of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# Quick line of test code commented out here, use it to test if your matplotlib is working\n",
    "#resto_df.plot.bar(x='name',y='rating')\n",
    "\n",
    "# Describe is a very useful function built into PD!\n",
    "resto_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ... lets try some working with some real data.\n",
    "- Use Pandas to open the Titanic Passenger Data\n",
    "  - One of the reasons pandas is so useful is that it give us amazing tools to handle info\n",
    "- Create some graphs and stats for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset and docs available at: \n",
    "# https://pandas.pydata.org/pandas-docs/stable/getting_started/intro_tutorials/06_calculate_statistics.html\n",
    "titanic = pd.read_csv(\"data/titanic.csv\") \n",
    "# titanic\n",
    "titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Head and tail\n",
    "- These functions allow us to limit the number of rows we see\n",
    "- Very useful when have massive datasets but want to check what they look like...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# titanic.head(10)\n",
    "# titanic.tail(10)\n",
    "t_n_b = pd.concat([titanic.head(5),titanic.tail(5)]) # sneaky combine the two for first and last! \n",
    "t_n_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The describe function\n",
    "- Tell us the basic information about a dataframe, or a serries\n",
    "    - Works on all levels of your dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# titanic.describe()\n",
    "# titanic[\"Sex\"].describe()\n",
    "titanic[\"Age\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Value counts function\n",
    "- Tells us how many of each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Get a count of the number of passengers by Sex\n",
    "# titanic[\"Sex\"].value_counts(sort=False)\n",
    "\n",
    "titanic[\"Age\"].value_counts(sort=True).tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Groupby function\n",
    "- groupby allows us to summarize categorical values in a serries\n",
    "    - Excel has this function...\n",
    "    - Pandas does it better/on more data!\n",
    "        - The covid uk gov database... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](images/rand_karma.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](images/groupby_karma_result.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](images/groupby_max.JPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Pandas makes organizing your data pretty straightforward\n",
    "\n",
    "# Before we looked at age, but what about age and sex?\n",
    "#titanic[\"Age\"].describe()\n",
    "\n",
    "#titanic.groupby(\"Sex\").mean()\n",
    "\n",
    "titanic.groupby(\"Sex\")[\"Age\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Get a count of those that did, and did not survive, by sex\n",
    "# 0 = dead, 1 = alive\n",
    "survived_df = titanic.groupby(\"Sex\")[\"Survived\"].value_counts(sort=False) # New operator 'value_counts'\n",
    "survived_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Lets plot the survivability\n",
    "survived_df.plot.bar(x='Sex',y=\"Survived\")\n",
    "\n",
    "# But... does this plot accord with what we know of the disaster? (hint: absolute vs relative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lets make this interesting\n",
    "- While making this lecture I got interested in harvesting Reddit.com data\n",
    "  - Reddit is an 'open api' meaning all the publically posted information is free to grab and play with\n",
    "      - For now...\n",
    "  - I've used an the Reddit Library PRAW (python reddit) to download a ton of Reddit data\n",
    "  - If you would like to know how I did that, I've included a python notebook in this week's files called RedditDataScraper\n",
    "- The dataset contains all the top level comments in the posts on the /r/Auckland subreddit as of start-2022\n",
    "  - 6,492 posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Lets take a look at what pandas sees\n",
    "# By defualt, pandas loads the top and bottom 10 items when we ask for information\n",
    "filename=\"data/old_rAuckland_top_comments.csv\"\n",
    "rAuckland_df = pd.read_csv(filename,parse_dates=[\"created_datetime\"]) # read the file and parse the datetime test as pandas datetime objets\n",
    "\n",
    "rAuckland_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# what are the stats of this? Headings/cols are a bit messy...\n",
    "rAuckland_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Now that we have a lot of data lets investigate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# lots of comments\n",
    "# usually not that much upvotes, though usually positive \n",
    "# there is at least one very negative post!\n",
    "rAuckland_df[\"comment_score\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# what does it look like as a plot?\n",
    "rAuckland_df[\"comment_score\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Investigation. When is the best time to post for max comments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# https://pandas.pydata.org/docs/getting_started/intro_tutorials/09_timeseries.html\n",
    "import matplotlib.pyplot as plt\n",
    "fig,axs = plt.subplots(figsize=(12,4))\n",
    "# Take a look how the operators have been chained together here...\n",
    "rAuckland_df.groupby(rAuckland_df[\"created_datetime\"].dt.hour)[\"comment_score\"].max().plot(kind='bar',rot=0,ax=axs)\n",
    "plt.xlabel(\"hour of the day\");\n",
    "plt.ylabel(\"avg comment score\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Does comment length correlate to karma?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# https://pandas.pydata.org/docs/getting_started/intro_tutorials/10_text_data.html\n",
    "# Combining a call to pandas... with a built in python string function (len)\n",
    "rAuckland_df[\"comment_length\"] = rAuckland_df[\"comment_body\"].str.len() \n",
    "rAuckland_df.plot.scatter(y=\"comment_score\",x=\"comment_length\",alpha=0.5,figsize=(12,6),logx=True) # Check out the axis!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Investigation. Who has the most single comment karma from r/auckland?\n",
    "- To answer this question we have to do something quite algorithmically taxing, groupby\n",
    "  - To group all of the posts that are related to specific users, we have to sort, then summarize\n",
    "  - In this groupby clause we use the .max() method that sums as it goes. Its kind of like the summary statistic you can add to a spatial join function in ArcGIS (*boo-hiss*) or QGIS (*yaaaay*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(figsize=(12,4))\n",
    "# In this clause we use groupby. its a taxing operation... bit of a pause here as it thinks..\n",
    "# Also, wow we would need to do something about those x-axis labels\n",
    "rAuckland_df.groupby(rAuckland_df[\"comment_author\"])[\"comment_score\"].max().plot(kind='bar',rot=0,ax=axs)\n",
    "plt.xlabel(\"comment author\");\n",
    "plt.ylabel(\"avg comment score\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Final investigation. What user has the highest karma, from r/Auckland?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Create a new series 'k' by grouping name with summed karma\n",
    "k = rAuckland_df.groupby(rAuckland_df[\"comment_author\"])[\"comment_score\"].sum() \n",
    "# Convert the series to a dataframe (series 1 col, df many cols)\n",
    "l = pd.DataFrame(k) \n",
    "# Output a sorted version, and make permanent\n",
    "l.sort_values(by=[\"comment_score\"],ascending=False,inplace=True)\n",
    "\n",
    "# The default version of this is too big a table, so lets just grab\n",
    "# the top and bottom 5\n",
    "overall_karma = pd.concat([l.head(5),l.tail(5)])\n",
    "overall_karma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "overall_karma.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Geopandas\n",
    "- Geopandas is the same as pandas with two important differences\n",
    "  1. it creates the 'geoSeries'\n",
    "  2. it creates the 'geoDataFrame'\n",
    "![](images/geopandas_logo.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### First, install geopandas\n",
    "\n",
    "- Open the Anaconda Prompt\n",
    "  - conda install -c conda-forge geopandas\n",
    "- https://geopandas.org/getting_started.html\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">(base) C:\\Users\\YOUR_USERNAME> conda install -c conda-forge geopandas\n",
    "</code>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Then test in the installation\n",
    "- To see if it works, just import the library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Useful packages\n",
    "- Geopandas (duh!)\n",
    "- folium (we will install this in a bit)\n",
    "  - if there is issue, ask in lab!\n",
    "- fiona (pre-installed: data import and export using GDAL tools)\n",
    "- PySAL (not needed yet: spatial analysis)\n",
    "- cartoPy (pre-installed:cartographic and projection)\n",
    "- shapely (pre-installed:already installed with pandas, but handles the geometery\n",
    "\n",
    "- remember pip and conda!\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">(base) C:\\Users\\YOUR_USERNAME> pip install Descarts \n",
    "</code>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Geopandas uses the same strucutre but adds geometry\n",
    "![](images/geodataframe.png)\n",
    "- https://geopandas.org/getting_started/introduction.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What is geometry?\n",
    "- Good question. \n",
    "  - The purpose of geopandas is to add geometry (spatial) data\n",
    "  - But its also to add spatial operations, too. \n",
    "- First however we do need to know what geometry is:\n",
    "  - Its a represenatation of a spatial location\n",
    "    - It can only have one CRS (coordinate reference system)\n",
    "  - It can come in several types, well beyond point, line, and polygon\n",
    "    - We can actually mix points, lines, and polygons in the same geodataframe\n",
    "      - I _really_ don't recommend this. It's like mixing array items, but worse\n",
    "  - Spatial inforamtion is stored as spatially encoded objects (using a library called _shapely_ but we don't really need to know about it, it in turn is built on GDAL)\n",
    "- Lets use an example we are familiar with and make it spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Return of our toy dict!\n",
    "mydict = {\n",
    "    \"restaurants\":[\n",
    "        {\n",
    "            \"name\":\"McDonalds\",\n",
    "            \"nickname\":\"Maccas\",\n",
    "            \"known-for\":\"Big Mac\",\n",
    "            \"likely-result\":\"heart-Attack\",\n",
    "            \"rating\":3            \n",
    "        },\n",
    "        {\n",
    "            \"name\":\"Burger King\",\n",
    "            \"nickname\":\"The King\",\n",
    "            \"known-for\":\"Whopper\",\n",
    "            \"rating\":2\n",
    "        },\n",
    "        {\n",
    "            \"name\":\"Burger Wisconsin\",\n",
    "            \"nickname\":\"Burg-Wickies\",\n",
    "            \"known-for\":\"Expensive Trash!\",            \n",
    "        },\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Now add a spatial location for it\n",
    "- Ripped from Google Maps\n",
    "![](images/burger_location_gmaps.JPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Add the lat/lon\n",
    "mydict = {\n",
    "    \"restaurants\":[\n",
    "        {\n",
    "            \"name\":\"McDonalds\",\n",
    "            \"nickname\":\"Maccas\",\n",
    "            \"known-for\":\"Big Mac\",\n",
    "            \"likely-result\":\"heart-Attack\",\n",
    "            \"rating\":3,\n",
    "            \"longitude\":174.7650551,\n",
    "            \"latitude\":-36.8500934,\n",
    "        },\n",
    "        {\n",
    "            \"name\":\"Burger King\",\n",
    "            \"nickname\":\"The King\",\n",
    "            \"known-for\":\"Whopper\",\n",
    "            \"rating\":2,\n",
    "            \"longitude\":174.76595,\n",
    "            \"latitude\":-36.8462059,\n",
    "        },\n",
    "        {\n",
    "            \"name\":\"Burger Wisconsin\",\n",
    "            \"nickname\":\"Burg-Wickies\",\n",
    "            \"known-for\":\"Expensive Trash!\",\n",
    "            \"longitude\":174.7459792,\n",
    "            \"latitude\":-36.855049\n",
    "        },\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convert to dataframe-like dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Same again on the convert front...\n",
    "restos = {\n",
    "    \"name\":[],\n",
    "    \"nickname\":[],\n",
    "    \"known-for\":[],\n",
    "    \"likely-result\":[],\n",
    "    \"rating\":[],\n",
    "    \"latitude\":[],\n",
    "    \"longitude\":[],\n",
    "}\n",
    "\n",
    "for r in mydict[\"restaurants\"]:\n",
    "    restos[\"name\"].append(r.get(\"name\")) # the data is set to None if it does not exist\n",
    "    restos[\"nickname\"].append(r.get(\"nickname\"))\n",
    "    restos[\"known-for\"].append(r.get(\"known-for\"))\n",
    "    restos[\"likely-result\"].append(r.get(\"likely-result\"))\n",
    "    restos[\"rating\"].append(r.get(\"rating\")) \n",
    "    restos[\"latitude\"].append(r.get(\"latitude\")) \n",
    "    restos[\"longitude\"].append(r.get(\"longitude\")) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "restos_df = pd.DataFrame(restos) # make a dataframe\n",
    "\n",
    "# Use geopandas to take the raw floats of the lat lon and turn them into a geospatially meaningful object\n",
    "restos_gdf = geopandas.GeoDataFrame(\n",
    "    restos_df, geometry=geopandas.points_from_xy(restos_df.longitude, restos_df.latitude))\n",
    "\n",
    "# POINT\n",
    "print(restos_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Get the built in basic outlines... (soon to be depreceated but I will ignore until forced heh)\n",
    "world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\n",
    "\n",
    "# We restrict to New Zealand\n",
    "ax = world[world.name == 'New Zealand'].plot(color='white', edgecolor='black')\n",
    "\n",
    "# We can now plot our ``GeoDataFrame``.\n",
    "restos_gdf.plot(ax=ax, color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Things we can do with geopandas\n",
    "- Geopandas is primarilly used for data manipulation. \n",
    "- Most of the analysis and cartographic operations are handled by other packages that integrate well with pandas \n",
    "- Pandas is great with spatial data mangement though and this means we can\n",
    "  - Join data (table join and spatial join) \n",
    "- Today we are just going to cover the basics. \n",
    "  - Getting data into geopandas\n",
    "    - Create some data from stractch (done!)\n",
    "    - Open some data in a csv file with x,y locations\n",
    "    - Open a shapefile\n",
    "  - Style the data with plots and background maps\n",
    "    - Take a look at folium\n",
    "  - Adding data to spatial data\n",
    "    - Table join\n",
    "    - Spatial join\n",
    "  - Basic geo-stats\n",
    "    - Just some little things for your assignments. nothing major.\n",
    "    - Area, length, overlay, search\n",
    "  \n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Loading data\n",
    "- Really easy to do with geopandas.\n",
    "- Here is how you load a shapefile\n",
    "  - Note here that we are actually loading a zip file!\n",
    "    - This is simply awesome that we can do this, as it means we no longer have to mess about with .shp .shx .prj .dbf\n",
    "    - You can actually store your entire dataset in a zip file with multiple folders and datasets. it is simply fantastic!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Requires fiona, conda install fiona\n",
    "import geopandas\n",
    "data_location = \"zip://data/doc-tracks.zip\" # a string to hold the file location (relative path!)\n",
    "tracks_gdf = geopandas.read_file(data_location) # read the file\n",
    "tracks_gdf.head()\n",
    "\n",
    "## helpful tip!\n",
    "# if you only want to test that things are working you can tell pandas to only load a few spatial features\n",
    "# all you have to do is send is the rows argument\n",
    "# https://geopandas.org/docs/user_guide/io.html\n",
    "#test_tracks_gdf = geopandas.read_file(data_location, rows=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- And we can have a look at the data too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# tracks_gdf.head() # show me the rows\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\n",
    "\n",
    "# We restrict to New Zealand - a spatial filtering operations!\n",
    "ax = world[world.name == 'New Zealand'].plot(\n",
    "    color='white', edgecolor='black')\n",
    "tracks_gdf.plot(ax=ax, color='red')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The matplotlib map looks cool in a retro way\n",
    "- What we really want is to make it look like a modern web map\n",
    "- We can use the folium library\n",
    "- Install folium using\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">(base) C:\\Users\\YOUR_USERNAME> pip install folium \n",
    "</code>\n",
    "</p>\n",
    "\n",
    "- or if you are using the geo_env (on a lab computer)\n",
    "\n",
    "<p style=\"background:black\">\n",
    "<code style=\"background:black;color:white\">(geo_env) C:\\Users\\YOUR_USERNAME> conda install -c conda-forge folium \n",
    "</code>\n",
    "</p>\n",
    "\n",
    "- Folium also works great with the Python API for GEE map display, just for those folks interested in that side of things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas\n",
    "import folium # this requires folium to be installed. from cmd.exe prompt use: pip install folium\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from shapely.geometry import Point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Other maps to try: tiles='OpenStreetMap' , tiles='Stamen Toner' , 'cartodbpositron'\n",
    "map = folium.Map(location = [-39.8,174.7], tiles = \"Stamen Terrain\", zoom_start = 6)\n",
    "\n",
    "# folium is a lot like leaflet\n",
    "# folium only accepts geojson files\n",
    "gjson = tracks_gdf.to_crs(epsg='4326').to_json() # convert to geojson, and make sure the shapfile is in WGS84 (SRID:4326)\n",
    "lines = folium.features.GeoJson(gjson) # use the geojson variable, and create the features in folium format\n",
    "\n",
    "map.add_child(lines) # add the data to folium, 'child' is what folium calls layers\n",
    "map # show the map, ooo it be interactive!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- If you want to know more, I found [this website useful](https://ocefpaf.github.io/python4oceanographers/blog/2015/12/14/geopandas_folium/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Geodataframes are pandas dataframes too\n",
    "- Because the geodataframe is built on top of the pandas library, we can actually do everything we could do with pandas before.\n",
    "  - For example, we could describe and plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "tracks_gdf.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "tracks_gdf[\"STLength\"].plot.line()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What about csv, thanks.\n",
    "- Yes csv are totally possible too. \n",
    "  - Open the csv as a pandas dataframe\n",
    "  - Convert to geopandas \n",
    "  - Et Volia!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "file_location = 'data/myLocations.csv'\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "myLocations_df = pd.read_csv(file_location)\n",
    "\n",
    "myLocations_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "myLocations_gdf = geopandas.GeoDataFrame(myLocations_df,geometry=geopandas.points_from_xy(myLocations_df.x,myLocations_df.y),crs='EPSG:4326')\n",
    "myLocations_gdf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# other maps to try: tiles='OpenStreetMap' , tiles='Stamen Toner' , 'cartodbpositron'\n",
    "myLocations_map = folium.Map(location = [-39.8,174.7], tiles = \"Stamen Toner\", zoom_start = 6)\n",
    "\n",
    "myLocations_gjson = myLocations_gdf.to_json() # convert to geojson (it is already in wgs84)\n",
    "myLocations_points = folium.features.GeoJson(myLocations_gjson) # use the geojson variable, and create the features in folium format\n",
    "\n",
    "myLocations_map.add_child(myLocations_points) # add the data to folium\n",
    "myLocations_map # show the map\n",
    "\n",
    "# fun fact! \n",
    "# if you need to create random coordiates, use the following excel equations\n",
    "# =RANDBETWEEN(-4160,-3700)/100\n",
    "# =RANDBETWEEN(17300,17800)/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Adding data using a join\n",
    "- Before now, we haven't used any kind of data joins. \n",
    "- But, as you may know, joining data is a big thing in GIS\n",
    "  - Joins allow us to link multiple datasets together\n",
    "  - Joins allow us to easily make non-spatial data -> spatial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Doing table joins is actually not a geopandas thing, its a pandas thing.\n",
    "  - We could have done this before the break, but we didn't really need to \n",
    "  - Using pandas, we can table joins realtively easily.\n",
    "- Lets consider the previous geopandas data table, and some data we want to join to it  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "myLocations_gdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "myLocations_joinData_df = pd.read_csv('data/myLocations_tableJoin.csv')\n",
    "myLocations_joinData_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### In Geopandas we use merge for a table join\n",
    "- Furthermore, we use a 'left join'\n",
    "  - A left join means that the features on the left (original) table will be preserved\n",
    "  - More on this when we talk about databases...\n",
    "- The operation is done 'on' the geodataframe\n",
    "- The result of the operation makes a new geoDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# To make things simple, make the joining fields have the same name.\n",
    "myLocations_joinData_df\n",
    "joined_gdf = myLocations_gdf.merge(myLocations_joinData_df,how='left',left_on='name',right_on='location_name')\n",
    "joined_gdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Okay, but we want spatial joins!\n",
    "- We are a gis class after all.\n",
    "- In the data folder, I've included the SA2 (statistical Area 2 shapefile)\n",
    "- In our Spatial Join, we are going to append the names of the SA2 to the random locations that we've been adding to above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# First we need to open our shapefile\n",
    "data_location = \"zip://data/SA2.zip\" # a string to hold the file location\n",
    "\n",
    "# Note that we are taking it straight from the zip. PANDAS POWER!\n",
    "SA2_gdf = geopandas.read_file(data_location,crs='EPSG:4326') # read the file\n",
    "SA2_gdf.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The operation name for a spatial join is sjoin\n",
    "  - Info on [sjoin](https://geopandas.org/docs/user_guide/mergingdata.html)\n",
    "  - sjoin takes the parameter 'op' to represent the topology rule for the spatial join\n",
    "    - For example: intersects, contains, within, touches, overlaps\n",
    "  - It also uses 'how' and we'll use the same as before 'left' for a left join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Note the left join again, and the spatial style of operation (op)\n",
    "sjoined_gdf = geopandas.sjoin(joined_gdf, SA2_gdf, op='intersects',how='left')\n",
    "\n",
    "sjoined_gdf.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Last Thing.\n",
    "- Can we do analysis with geopandas?\n",
    "  - yes we can :)\n",
    "  - buffer\n",
    "  - dissolve\n",
    "  - area/length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Back to our trusty doc-tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import geopandas\n",
    "data_location = \"zip://data/doc-tracks.zip\" # a string to hold the file location\n",
    "tracks_gdf = geopandas.read_file(data_location) # read the file, but really lets not go overboard\n",
    "tracks_gdf = tracks_gdf.head(100)\n",
    "tracks_gdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Buffer\n",
    "- This falls under ['Geometric Manipluations'](https://geopandas.org/docs/user_guide/geometric_manipulations.html)\n",
    "  - Other similar operations include:\n",
    "    - envelope (extent)\n",
    "    - centroid (center)\n",
    "    - simplify\n",
    "    - intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# first change to NZTM 2000 so we can measure properly in meters\n",
    "tracks_gdf = tracks_gdf.to_crs(epsg=\"2193\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# buffer the tracks, in map units (will be defined by your CRS)\n",
    "buffer_tracks = tracks_gdf.buffer(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Other maps to try: tiles='OpenStreetMap' , tiles='Stamen Toner' , 'cartodbpositron'\n",
    "map = folium.Map(location = [-39.8,174.7], tiles = \"Stamen Terrain\", zoom_start = 6)\n",
    "\n",
    "gjson = buffer_tracks.to_crs(epsg='4326').to_json() # convert to geojson, and make sure the shapfile is in WGS84 (SRID:4326)\n",
    "lines = folium.features.GeoJson(gjson) # use the geojson variable, and create the features in folium format\n",
    "\n",
    "map.add_child(lines) # add the data to folium\n",
    "map # show the map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dissolve\n",
    "- Dissolve is both a spatial dissolve and a aggregate function, like groupby. \n",
    "  - As a result, we need to give it a attribute field (series) to groupby, even if we don't need it.\n",
    "  - We can append a series that just equals 1 for the whole column for our purposes.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "buffer_tracks = geopandas.GeoDataFrame(geometry=buffer_tracks.geometry)\n",
    "\n",
    "buffer_tracks['disfield'] =1 # dummy value\n",
    "b= buffer_tracks.dissolve(by='disfield') # Note the type of geometry that this generates\n",
    "b.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# other maps to try: tiles='OpenStreetMap' , tiles='Stamen Toner' , 'cartodbpositron'\n",
    "map = folium.Map(location = [-39.8,174.7], tiles = \"Stamen Terrain\", zoom_start = 6)\n",
    "\n",
    "# folium is a lot like leaflet\n",
    "# folium only accepts geojson files\n",
    "gjson = b.to_crs(epsg='4326').to_json() # convert to geojson, and make sure the shapfile is in WGS84 (SRID:4326)\n",
    "lines = folium.features.GeoJson(gjson) # use the geojson variable, and create the features in folium format\n",
    "\n",
    "map.add_child(lines) # add the data to folium\n",
    "map # show the map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Area and Length\n",
    "- These are built in pretty easily\n",
    "- For area of a polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "buffer_tracks.head(5)\n",
    "buffer_tracks.area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "buffer_tracks[\"area\"] = buffer_tracks.area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "buffer_tracks.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Length\n",
    "- Length is the same thing, but we need to use a line\n",
    "  - We can use the tracks file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "data_location = \"zip://data/doc-tracks.zip\" # a string to hold the file location\n",
    "tracks_gdf = geopandas.read_file(data_location) # read the file\n",
    "tracks_gdf.head()\n",
    "\n",
    "final_example = tracks_gdf.head(10).to_crs(epsg='4326') # Expect a red box to pop up due to this...\n",
    "final_example[\"length_of_track\"] = final_example.length\n",
    "final_example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Wait a second... \n",
    "- those length values are off. why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "data_location = \"zip://data/doc-tracks.zip\" # a string to hold the file location\n",
    "tracks_gdf = geopandas.read_file(data_location) # read the file\n",
    "tracks_gdf.head()\n",
    "# first change to NZTM 2000 so we can measure properly in meters\n",
    "tracks_gdf = tracks_gdf.to_crs(epsg=\"2193\")\n",
    "\n",
    "\n",
    "final_example = tracks_gdf.head(10).copy() # easier if we copy of the object to keep things clean...\n",
    "final_example[\"length_of_track\"] = final_example.length\n",
    "final_example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Searching for a specific item in the Geopandas Dataframe\n",
    "- One of the important things you can do with pandas is to use the 'loc' function. it allows us to 'search' in out data. \n",
    "  - You can find a specific name, or evaluate a boolean. \n",
    "    - The boolean operations allo use to 'select' data like, find all highways with a speed limit of 100kph or higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "data_location = \"zip://data/SA2.zip\" # A string to hold the file location\n",
    "SA2_gdf = geopandas.read_file(data_location,crs='EPSG:4326') # Read the file\n",
    "poly = SA2_gdf.loc[SA2_gdf['SA22018__1']=='Coromandel'] # Find a specific SA2 by name\n",
    "poly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Find all of the really large land areas of SA2's\n",
    "poly = SA2_gdf.loc[SA2_gdf['LAND_AREA_']>5000]\n",
    "poly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### And thats all, folks!\n",
    "- We covered a lot of ground today\n",
    "  - Dictionaries\n",
    "  - Pandas\n",
    "  - Geopandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Homework\n",
    "\n",
    "### 1. Create a pandas dataframe from the dictionary in the cell below, then tell me Michael's average in the series \"karma\". Round down to the nearest whole number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "postdata = {'posts': [{'author': 'Michael', 'postid': 22, 'karma': 15},\n",
    "  {'author': 'Michael', 'postid': 23, 'karma': 15},\n",
    "  {'author': 'Michael', 'postid': 25, 'karma': 6},\n",
    "  {'author': 'Michael', 'postid': 26, 'karma': 200},\n",
    "  {'author': 'Michael', 'postid': 27, 'karma': 76},\n",
    "  {'author': 'Michael', 'postid': 28, 'karma': 2},\n",
    "  {'author': 'Sila', 'postid': 29, 'karma': 73},\n",
    "  {'author': 'Michael', 'postid': 30, 'karma': 3},\n",
    "  {'author': 'Michael', 'postid': 31, 'karma': 1},\n",
    "  {'author': 'Michael', 'postid': 32, 'karma': 5},\n",
    "  {'author': 'Michael', 'postid': 33, 'karma': 15},\n",
    "  {'author': 'Michael', 'postid': 34, 'karma': 54},\n",
    "  {'author': 'Amber', 'postid': 35, 'karma': 15},\n",
    "  {'author': 'Michael', 'postid': 36, 'karma': 16},\n",
    "  {'author': 'Michael', 'postid': 37, 'karma': 65},\n",
    "  {'author': 'Michael', 'postid': 38, 'karma': 25},\n",
    "  {'author': 'Michael', 'postid': 39, 'karma': 66},\n",
    "  {'author': 'Michael', 'postid': 40, 'karma': 12},\n",
    "  {'author': 'Amber', 'postid': 41, 'karma': 32},\n",
    "  {'author': 'Michael', 'postid': 42, 'karma': 61},\n",
    "  {'author': 'Michael', 'postid': 43, 'karma': 63},\n",
    "  {'author': 'Michael', 'postid': 44, 'karma': 78},\n",
    "  {'author': 'Sila', 'postid': 45, 'karma': 63},\n",
    "  {'author': 'Michael', 'postid': 46, 'karma': 98},\n",
    "  {'author': 'Michael', 'postid': 47, 'karma': 97},\n",
    "  {'author': 'Michael', 'postid': 48, 'karma': 16},\n",
    "  {'author': 'Sila', 'postid': 49, 'karma': 96},\n",
    "  {'author': 'Michael', 'postid': 50, 'karma': 22},\n",
    "  {'author': 'Michael', 'postid': 51, 'karma': 33},\n",
    "  {'author': 'Michael', 'postid': 52, 'karma': 6},\n",
    "  {'author': 'Amber', 'postid': 53, 'karma': 66},\n",
    "  {'author': 'Michael', 'postid': 54, 'karma': 47},\n",
    "  {'author': 'Michael', 'postid': 55, 'karma': 32},\n",
    "  {'author': 'Michael', 'postid': 56, 'karma': 15}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2. In the supplied zip file \"doc-regions\" (in the data directory), What is the name of the smallest region by area?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
