---
title: "Python Data Bootcamp - Geopandas 1"
subtitle: ": An Introduction to Geospatial Analysis with Python"
date: 03/21/2025
date-format: long
author:
  - name: Hyesop Shin
    orcid: 0000-0003-2637-7933
    email: hyesop.shin@auckland.ac.nz
    affiliations:
      - name: University of Auckland
        address: 23 Symonds Street
        city: Auckland
        postal-code: 1010
format: 
  revealjs:
      logo: Figs/uoa-logo.png
      css: logo.css
      slide-number: true
      show-slide-number: print
editor: source
include-in-header:
  - text: |
      <style type="text/css">
      ul li ul li {
        font-size: 0.7em;
      }
      </style>
---


## Recap of Previous Lecture

- Descriptive Statistics
- Aggregation using `groupby`
- Merging dataframes
- Data Vis


## Today's Lecture
* Little bit of `pandas`
* Lots of GIS functions exist
* We are not going to cover everything such as:
   - Intersect
   - Buffer
   - Clip


## Melt and Cast {.smaller}

![](https://hausetutorials.netlify.app/posts/2020-05-14-reshaping-data-in-python-pandas/pic5.png){fig-align=center}

* Pandas `melt()` function is used to change the DataFrame format from wide to long.
* It‚Äôs used to create a specific format of the DataFrame object where one or more columns work as identifiers.
* All the remaining columns are treated as values and unpivoted to the row axis and only two columns ‚Äì variable and value.
* We can use `pivot()` function to unmelt the output DataFrame back to the original data frame.


## Melt and Cast 

```python
df = pd.DataFrame({
    'City': ['Auckland', 'Wellington', 'Christchurch'],
    'Jan_Temp': [25, 22, 20],
    'Feb_Temp': [24, 21, 19],
    'Mar_Temp': [23, 20, 18]
})

print("Original DataFrame:")
print(df)

# Using melt to reshape the DataFrame
df_melted = pd.melt(df, id_vars=['City'], var_name='Month', value_name='Temperature')

print("\nMelted DataFrame:")
print(df_melted)
```

## Data Vis

```python
import seaborn as sns
import matplotlib.pyplot as plt

# Set a clean style
sns.set(style="whitegrid")

# Plot
plt.figure(figsize=(10, 6))
sns.lineplot(data=df_melted, x='Month', y='Temperature', hue='City', marker='o')

# Add titles and labels
plt.title('Monthly Temperatures Across Cities', fontsize=16)
plt.xlabel('Month')
plt.ylabel('Temperature (¬∞C)')
plt.xticks(rotation=45)
plt.legend(title='City')
plt.tight_layout()

# Show plot
plt.show()
```

## Two fundamental geographic data models



:::: {.columns}

::: {.column width="50%"}

![](Figs/howwemap.png)

:::


::: {.column width="50%"}
Vector = precise & structured.
Raster = continuous & consistent
:::

::::

## Vector vs Raster Data Models {.smaller}

| **Aspect**         | **Vector Model**                                      | **Raster Model**                                         |
|--------------------|--------------------------------------------------------|-----------------------------------------------------------|
| **Data Type**      | Points, Lines, Polygons                               | Grid of uniform cells (pixels)                           |
| **Boundaries**     | Discrete, well-defined                                | Aggregated, based on resolution                          |
| **Precision**      | High precision (exact shapes & locations)             | Lower precision, depends on cell size                    |
| **Scalability**    | Scales with complexity                                | Consistent and scalable over space                       |
| **Common Uses**    | Parcels, roads, boundaries                            | Satellite imagery, aerial photos, land cover             |
| **Applications**   | Accurate mapping, cadastre, infrastructure            | Background layers, remote sensing, environmental models  |


## Which data to use

* Vector datasets and methods dominate the social sciences because human settlements and processes (e.g., transport infrastructure) tend to have discrete borders
* Raster datasets and methods dominate many environmental sciences because of the reliance on remote sensing data

## Python Tools for Vector and Raster Data

### üü¢ Vector Data

| Package      | Level     | Description                                                                 |
|--------------|-----------|-----------------------------------------------------------------------------|
| `shapely`    | Low-level | Handles individual geometry objects (points, lines, polygons)               |
| `geopandas`  | High-level| Works with GeoSeries & GeoDataFrames (vector layers); built on shapely      |

<!-- ‚û°Ô∏è **GeoPandas** is the core of the vector data ecosystem in Python. -->

---

### üü° Raster Data

| Package       | Focus      | Description                                                                 |
|---------------|------------|-----------------------------------------------------------------------------|
| `rasterio`    | Simple rasters | Uses `numpy` arrays + metadata dictionary (CRS, transform, etc.)            |
| `xarray`      | Complex rasters | Uses `xarray.Dataset` and `DataArray`; ideal for NetCDF & multi-band rasters |

<!-- ‚û°Ô∏è This course focuses on **rasterio** for raster processing. -->


## Geospatial data in Python 

* A couple of terminology notes
    _ A feature refers to both the geometry and attributes of specific piece of vector data
    - A feature collection is a list, or collection, of features
    
* Common formats for vector datasets
    - A shapefile
    * Mandatory files:
    * shp: the file containing the geometries
    * .shx: the file that indexes the geometry
    * .dbf: tabular data format storing the attributes for each geometry
    * And many optional files for documentation, projection information, etc.

* geopackage (gpkg), geojson, gdb, tif, img, parquet...


## Reading and Writing Spatial Data

### Reading Data
- Use `gpd.read_file()` to read various spatial data formats (e.g., Shapefiles, GeoJSON)

```python
  import geopandas as gpd
  nzpop = gpd.read_file('path_to_file.shp')
```

---

### Writing Data

Use `gpd.to_file()` to write GeoDataFrames to different formats

```python
nzpop.to_file('path_to_save_file.shp')
```

## Analysing vector data with GeoPandas

```python
import geopandas as gpd
countries = gpd.read_file("./data/ne_110m_admin_0_countries")
countries.head()
```


```
iso_a3	name	              continent	    pop_est	  gdp_md_est	  geometry
AFG	    Afghanistan        Asia	        34124811	64080	        POLYGON ((61.21082 ...
AGO	    Angola             Africa	      29310273	189000	        MULTIPOLYGON (((23.9...
ALB	    Albania            Europe	      3047987	  33900	        POLYGON ((21.02004 ...
ARE	    UAE                Asia	        6072475	  667200	        POLYGON ((51.57952 ...
ARG	    Argentina          S. America	  44293293	879400	        MULTIPOLYGON (((-66...
...
```

```python
type(countries)
```

```
geopandas.geodataframe.GeoDataFrame
```


## What is a geodataframe

![](https://miro.medium.com/v2/resize:fit:1238/1*x9gF-ZVR4JMAv3cTH6LtfA.png){fig-align=center}

* Just like a DataFrame but with a new, special geometry column:

```python
countries["geometry"].head(n=3)
```

```
0    POLYGON ((61.21082 35.65007, 62.23065 35.27066...
1    MULTIPOLYGON (((23.90415 -11.72228, 24.07991 -...
2    POLYGON ((21.02004 40.84273, 20.99999 40.58000...
Name: geometry, dtype: geometry
```

Take a look at the first geometry polygon by using the .iloc[] selector:
```
countries['geometry'].iloc[0]
```

## We can still leverage the power of pandas
Calculate the total world population:

```python
countries["pop"].sum() / 1e9  # In billions
```

```
7.150238276
```

Calculate the total population on each continent:
```python
grouped = countries.groupby("continent")
grouped
```

Access the ‚Äúpop‚Äù column from the groupby variable (‚Äúgrouped‚Äù) and then call the .sum() function to calculate our desired statistic:

*The groupby() function does not return a DataFrame ‚Äî you need to call sum(), mean() etc, or apply() a function to get your desired result!*

```python
pop_by_continent = grouped["pop"].sum()

pop_by_continent
```


## Filter dataframe

Filter the data frame based on a boolean selection:

```
# Is the country name NZ?
is_NZ = countries["name"] == "New Zealand"

is_NZ
```



```
# Get the row with USA
NZ = countries.loc[is_NZ]

NZ
```

## `Squeeze`

The squeeze() function does just one it sounds like: if you have a DataFrame with only one row, it will ‚Äúsqueeze‚Äù the row dimension by removing it, returning just a Series object:

```python
NZ.squeeze().geometry
```

```python
# Squeeze
NZsqueezed = NZ.squeeze()

# Print out the types
print("The type of NZ is: ", type(NZsqueezed))

# Output
NZsqueezed
```


## Coordinate Reference Systems (CRS)
- Importance of CRS in spatial data
- Using `.crs` to check CRS
- Setting CRS during data read/write operations
- `print(countries.crs)`

```
<Geographic 2D CRS: EPSG:4326>
Name: WGS 84
Axis Info [ellipsoidal]:
- Lat[north]: Geodetic latitude (degree)
- Lon[east]: Geodetic longitude (degree)
Area of Use:
- name: World.
- bounds: (-180.0, -90.0, 180.0, 90.0)
Datum: World Geodetic System 1984 ensemble
- Ellipsoid: WGS 84
- Prime Meridian: Greenwich
```

## The EPSG=4326 CRS {.smaller}
* EPSG 4326 is known as WGS 84 where x and y are longitude and latitude.
* It is is the default coordinate system for GPS systems.
* It‚Äôs also known as Plate Carr√©e or equirectangular

```python
# Create a figure and axes
fig, ax = plt.subplots(figsize=(10, 6))
# Plot the countries on our axes
ax = countries.plot(ax=ax, facecolor="none", edgecolor="black")
# Add a title
ax.set_title("Equirectangular Projection");
```
![](https://musa-550-fall-2023.github.io/content/week-3/imgs/equirectangular.png){fig-align=center}


## Can we convert to other coordinate systems? {.smaller}
* Use the `df.to_crs()` function! The most well-known projections can be specified by their EPSG code.
* Geopandas documentation on re-projecting: [Managing Projections](https://geopandas.org/en/stable/docs/user_guide/projections.html)
* Let‚Äôs convert to the Mercator projection

```python
no_antarctica = countries.loc[(countries["name_long"] != "Antarctica")]
# Two ways to specify the EPSG code
countries_mercator = no_antarctica.to_crs(epsg=3395)
# Alternatively:
# countries_mercator = no_antartica.to_crs("EPSG:3395")
countries_mercator.head()
```

![](https://musa-550-fall-2023.github.io/content/week-3/imgs/mercator.png){fig-align=center}


## Let's try another dataset
* This time we can try some points

```python
data = {
    "Name": ["New York City", "S√£o Paulo", "Tokyo", "Lagos", "Sydney"],
    "Population": [8419600, 12325232, 13929286, 15000000, 5312163],  # Approximate populations
    "Latitude": [40.7128, -23.5505, 35.6895, 6.5244, -33.8688],
    "Longitude": [-74.0060, -46.6333, 139.6917, 3.3792, 151.2093]
}
```

```
type(data)
```

```
dict
```

## Converting dataframe to geodataframe

```python
gdf = gpd.GeoDataFrame(
    cities_df, 
    geometry=gpd.points_from_xy(
        cities_df['Longitude'],
          cities_df['Latitude']
          )
        )
```


## Part 2: Spatial Relationships and Joins

Let‚Äôs explore joins and merges between GeoDataFrames based on geospatial relationships

```python
cities_url = "https://raw.githubusercontent.com/dataandcrowd/GISCI343/main/docs/Lecture4/data/ne_110m_populated_places.gpkg"
cities = gpd.read_file(cities_url)
cities.head()
```

## A quick example
What country is New York in?

```python
# Select the Point representing New York City
new_york = cities.loc[cities["name"] == "New York"].geometry.squeeze()

new_york
```

```python
type(new_york)
```

```
shapely.geometry.point.Point
```

```python
countries.contains(new_york)
```

```python
# Find the country that contains New York
countries.loc[countries.contains(new_york)]
```

```python
USA = countries.loc[countries.contains(new_york)].squeeze().geometry
USA

new_york.within(USA)
```

## Your turn
* Use the same code to find Auckland

## Spatial relationships: Functions

* `equals`
* `contains`
* `crosses`
* `disjoint`
* `intersects`
* `overlaps`
* `touches`
* `within`
* `covers`





## Summary
* To navigate complex datasets effectively, it's crucial to structure your code in a way that enhances readability and maintainability
* Python offers a rich ecosystem of libraries specifically designed for GIS and spatial analysis. We explored some key packages such as GeoPandas for spatial data frames
* The actual programming:
    - Pandas: Indexing, Filtering, Grouping, Join between dataframes
    - Geopandas: Hands-on experience in GIS using codes



## <br> Thanks! <br> Q & A {style="text-align: center;"}
